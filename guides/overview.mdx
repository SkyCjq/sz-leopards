Integrating LangWatch into your projects is designed to be a straightforward process. Regardless of the language or LLM service you are using, you can set up LangWatch with minimal configuration and start gathering valuable insights into your LLM's performance and user interactions. Here, we provide specific guides for integrating LangWatch with popular LLM services and libraries.

<CardGroup cols={2}>
  <Card title="Open AI python" icon="link" href="/guides/Open-AI-Python" />
  <Card
    title="Azure Open AI python"
    icon="link"
    href="/guides/Azure-Open-AI-Python"
  />
  <Card title="LangChain Python" icon="link" href="/guides/LangChain-Python" />
  <Card title="Custom Python" icon="link" href="/guides/custom-Python" />
  <Card
    title="Capturing additional spans and metadata"
    icon="link"
    href="/guides/capturing-additional-spans-and-metadata"
  />
  <Card title="REST API" icon="link" href="/guides/REST-API" />
</CardGroup>
