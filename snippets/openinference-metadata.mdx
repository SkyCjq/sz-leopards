## Capturing Metadata

You can use OpenInference's `using_attributes` context manager to capture additional information for your LLM calls, such as the user_id, session_id (equivalent to thread id), tags and metadata:

```python
from openinference.instrumentation import using_attributes

def main():
  with using_attributes(
      session_id="my-test-session",
      user_id="my-test-user",
      tags=["tag-1", "tag-2"],
      metadata={"foo": "bar"},
  ):
      completion = client.chat.completions.create(
        ...
      )
```