Integrating LangWatch into your projects is designed to be a straightforward process. Regardless of the language or LLM service you are using, you can set up LangWatch with minimal configuration and start gathering valuable insights into your LLM's performance and user interactions. Here, we provide specific guides for integrating LangWatch with popular LLM services and libraries.

<CardGroup cols={2}>
  <Card title="Python OpenAI" icon="link" href="./python/open-ai" />
  <Card title="TypeScript Integration" icon="link" href="./typescript/guide" />
  <Card
    title="Python Azure OpenAI"
    icon="link"
    href="./python/azure-open-ai"
  />
  <Card title="Python LangChain" icon="link" href="./python/langchain" />
  <Card title="Python Custom" icon="link" href="./python/custom" />
  <Card title="REST API" icon="link" href="./rest-api" />
</CardGroup>
